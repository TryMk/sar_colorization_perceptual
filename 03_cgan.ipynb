{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-8A_FyqqlTW"
      },
      "source": [
        "**Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_cqYIrb16lF",
        "outputId": "550d4abf-e80c-412c-8110-c070d79ab50b"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "6zdRk3XlnI8d"
      },
      "outputs": [],
      "source": [
        "# !unzip /content/drive/MyDrive/x.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Dx-NUNzpnS6Z"
      },
      "outputs": [],
      "source": [
        "# !mv /content/x/* /content/drive/MyDrive/prototype/Train/x/\n",
        "# !mv /content/y/* /content/drive/MyDrive/prototype/Train/y/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRJ_rGIXnidZ",
        "outputId": "029c5c99-a02e-4a12-a993-ccc6decdbca6"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# print(len(os.listdir('/content/drive/MyDrive/prototype/Train/x')))\n",
        "# print(len(os.listdir('/content/drive/MyDrive/prototype/Train/y')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Jan 16 14:54:29 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 561.17                 Driver Version: 561.17         CUDA Version: 12.6     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 2060      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
            "| 32%   53C    P8             20W /  160W |     624MiB /   6144MiB |      3%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A      2124    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
            "|    0   N/A  N/A      3704    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
            "|    0   N/A  N/A      4660    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
            "|    0   N/A  N/A      4716    C+G   ...__8wekyb3d8bbwe\\Notepad\\Notepad.exe      N/A      |\n",
            "|    0   N/A  N/A      6540    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe      N/A      |\n",
            "|    0   N/A  N/A      7868    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
            "|    0   N/A  N/A      8212    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
            "|    0   N/A  N/A      8612    C+G   ...ejd91yc\\AdobeNotificationClient.exe      N/A      |\n",
            "|    0   N/A  N/A      9740    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
            "|    0   N/A  N/A      9856    C+G   ...am Files\\Microsoft VS Code\\Code.exe      N/A      |\n",
            "|    0   N/A  N/A     11316      C   C:\\Program Files\\Python312\\python.exe       N/A      |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Wed_Oct_30_01:18:48_Pacific_Daylight_Time_2024\n",
            "Cuda compilation tools, release 12.6, V12.6.85\n",
            "Build cuda_12.6.r12.6/compiler.35059454_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.12.8\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Looking in links: c:\\Users\\ICTSUP~1\\AppData\\Local\\Temp\\tmpavvg8pid\n",
            "Requirement already satisfied: pip in c:\\program files\\python312\\lib\\site-packages (24.3.1)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pip in c:\\program files\\python312\\lib\\site-packages (24.3.1)\n"
          ]
        }
      ],
      "source": [
        "!python -m ensurepip --upgrade\n",
        "!python.exe -m pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: numpy in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (2.2.1)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pandas in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: Pillow in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (11.1.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: matplotlib in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.2.1)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tqdm in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (4.67.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Requirement already satisfied: torch in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchsummary in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (1.5.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from torch) (75.8.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (2.2.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ictsupport\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade numpy\n",
        "# !pip install --upgrade torch\n",
        "!pip install --upgrade pandas\n",
        "# !pip install --upgrade torchvision\n",
        "# !pip install --upgrade torchaudio\n",
        "!pip install --upgrade Pillow\n",
        "!pip install --upgrade matplotlib\n",
        "!pip install --upgrade tqdm\n",
        "# !pip install --upgrade torchsummary\n",
        "\n",
        "!pip3 install --upgrade torch torchvision torchaudio torchsummary --index-url https://download.pytorch.org/whl/cu124\n",
        "\n",
        "# !pip install --upgrade\n",
        "# !pip install --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZRRuC1Dcqkll"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.utils import save_image\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLt5R5-9lGOP"
      },
      "source": [
        "# Building Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1mQ7wbn3lM1K"
      },
      "outputs": [],
      "source": [
        "# Generator model (U-Net for SAR to RGB translation)\n",
        "# Define the downsampling block\n",
        "class DownSample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, apply_batchnorm=True):\n",
        "        super(DownSample, self).__init__()\n",
        "        layers = [\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False)\n",
        "        ]\n",
        "        if apply_batchnorm:\n",
        "            layers.append(nn.BatchNorm2d(out_channels))\n",
        "        layers.append(nn.LeakyReLU(0.2))\n",
        "        self.block = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "# Define the upsampling block\n",
        "class Upsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, apply_dropout=False):\n",
        "        super(Upsample, self).__init__()\n",
        "        layers = [\n",
        "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        ]\n",
        "        if apply_dropout:\n",
        "            layers.append(nn.Dropout(0.5))\n",
        "        self.block = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, skip_input):\n",
        "        x = self.block(x)\n",
        "        x = torch.cat((x, skip_input), 1)\n",
        "        return x\n",
        "\n",
        "# Generator adapted for SAR images\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=3):  # 1 input channel (SAR), 3 output channels (RGB)\n",
        "        super(Generator, self).__init__()\n",
        "        self.down1 = DownSample(in_channels, 64)\n",
        "        self.down2 = DownSample(64, 128)\n",
        "        self.down3 = DownSample(128, 256)\n",
        "        self.down4 = DownSample(256, 512)\n",
        "        self.down5 = DownSample(512, 512)\n",
        "        self.down6 = DownSample(512, 512)\n",
        "        self.down7 = DownSample(512, 512)\n",
        "        # self.down8 = DownSample(512, 512)\n",
        "\n",
        "        # self.up1 = Upsample(512, 512)\n",
        "        self.up2 = Upsample(512, 512)\n",
        "        self.up3 = Upsample(1024, 512)\n",
        "        self.up4 = Upsample(1024, 512)\n",
        "        self.up5 = Upsample(1024, 256)\n",
        "        self.up6 = Upsample(512, 128)\n",
        "        self.up7 = Upsample(256, 64)\n",
        "\n",
        "        self.final = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
        "            nn.Conv2d(128, out_channels, kernel_size=4, padding=1),  # 3 output channels (RGB)\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # U-NET generator with skip connections from encoder to decoder\n",
        "        d1 = self.down1(x)\n",
        "        d2 = self.down2(d1)\n",
        "        d3 = self.down3(d2)\n",
        "        d4 = self.down4(d3)\n",
        "        d5 = self.down5(d4)\n",
        "        d6 = self.down6(d5)\n",
        "        d7 = self.down7(d6)\n",
        "        # d8 = self.down8(d7)\n",
        "\n",
        "        # u1 = self.up1(d8, d7)\n",
        "        u2 = self.up2(d7, d6)\n",
        "        u3 = self.up3(u2, d5)\n",
        "        u4 = self.up4(u3, d4)\n",
        "        u5 = self.up5(u4, d3)\n",
        "        u6 = self.up6(u5, d2)\n",
        "        u7 = self.up7(u6, d1)\n",
        "        u8 = self.final(u7)\n",
        "\n",
        "        return u8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17ex5wfsqw84"
      },
      "source": [
        "# **Building Discriminator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cLoZEY90rnxk"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=4):\n",
        "        super(Discriminator, self).__init__()\n",
        "        def discriminator_block(in_filters, out_filters, stride=2, normalize=True):\n",
        "            \"\"\"Returns layers of each discriminator block\"\"\"\n",
        "            layers = [\n",
        "                nn.Conv2d(in_filters, out_filters, kernel_size=4, stride=stride, padding=1)\n",
        "                ]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm2d(out_filters))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(in_channels, 64, normalize=False),\n",
        "            *discriminator_block(64, 128),\n",
        "            *discriminator_block(128, 256),\n",
        "            *discriminator_block(256, 512, stride=1),\n",
        "            nn.Conv2d(512, 1, kernel_size=4, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img_A, img_B):\n",
        "        # Concatenate image and condition image by channels to produce input\n",
        "        img_input = torch.cat((img_A, img_B), 1)\n",
        "        return self.model(img_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qPASJvyYFdi2"
      },
      "outputs": [],
      "source": [
        "# Initialize generator and discriminator\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7gAhtEDuaWHp"
      },
      "outputs": [],
      "source": [
        "generator = generator.to(device)\n",
        "discriminator = discriminator.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzsHcsLxFfbM",
        "outputId": "a9868331-eb1c-419a-a804-9c83c01cd22f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discriminator(\n",
            "  (model): Sequential(\n",
            "    (0): Conv2d(4, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(discriminator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oklWXDMFtZu",
        "outputId": "9de5d941-24f2-498d-f932-e5b865f33878"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (down1): DownSample(\n",
            "    (block): Sequential(\n",
            "      (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "  )\n",
            "  (down2): DownSample(\n",
            "    (block): Sequential(\n",
            "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "  )\n",
            "  (down3): DownSample(\n",
            "    (block): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "  )\n",
            "  (down4): DownSample(\n",
            "    (block): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "  )\n",
            "  (down5): DownSample(\n",
            "    (block): Sequential(\n",
            "      (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "  )\n",
            "  (down6): DownSample(\n",
            "    (block): Sequential(\n",
            "      (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "  )\n",
            "  (down7): DownSample(\n",
            "    (block): Sequential(\n",
            "      (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "  )\n",
            "  (up2): Upsample(\n",
            "    (block): Sequential(\n",
            "      (0): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (up3): Upsample(\n",
            "    (block): Sequential(\n",
            "      (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (up4): Upsample(\n",
            "    (block): Sequential(\n",
            "      (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (up5): Upsample(\n",
            "    (block): Sequential(\n",
            "      (0): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (up6): Upsample(\n",
            "    (block): Sequential(\n",
            "      (0): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (up7): Upsample(\n",
            "    (block): Sequential(\n",
            "      (0): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (final): Sequential(\n",
            "    (0): Upsample(scale_factor=2.0, mode='nearest')\n",
            "    (1): ZeroPad2d((1, 0, 1, 0))\n",
            "    (2): Conv2d(128, 3, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "    (3): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pep47u9XIEa7",
        "outputId": "9f41a0c9-5981-4b5b-81dd-a599b6092464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 128, 128]           1,024\n",
            "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
            "         LeakyReLU-3         [-1, 64, 128, 128]               0\n",
            "        DownSample-4         [-1, 64, 128, 128]               0\n",
            "            Conv2d-5          [-1, 128, 64, 64]         131,072\n",
            "       BatchNorm2d-6          [-1, 128, 64, 64]             256\n",
            "         LeakyReLU-7          [-1, 128, 64, 64]               0\n",
            "        DownSample-8          [-1, 128, 64, 64]               0\n",
            "            Conv2d-9          [-1, 256, 32, 32]         524,288\n",
            "      BatchNorm2d-10          [-1, 256, 32, 32]             512\n",
            "        LeakyReLU-11          [-1, 256, 32, 32]               0\n",
            "       DownSample-12          [-1, 256, 32, 32]               0\n",
            "           Conv2d-13          [-1, 512, 16, 16]       2,097,152\n",
            "      BatchNorm2d-14          [-1, 512, 16, 16]           1,024\n",
            "        LeakyReLU-15          [-1, 512, 16, 16]               0\n",
            "       DownSample-16          [-1, 512, 16, 16]               0\n",
            "           Conv2d-17            [-1, 512, 8, 8]       4,194,304\n",
            "      BatchNorm2d-18            [-1, 512, 8, 8]           1,024\n",
            "        LeakyReLU-19            [-1, 512, 8, 8]               0\n",
            "       DownSample-20            [-1, 512, 8, 8]               0\n",
            "           Conv2d-21            [-1, 512, 4, 4]       4,194,304\n",
            "      BatchNorm2d-22            [-1, 512, 4, 4]           1,024\n",
            "        LeakyReLU-23            [-1, 512, 4, 4]               0\n",
            "       DownSample-24            [-1, 512, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 2, 2]       4,194,304\n",
            "      BatchNorm2d-26            [-1, 512, 2, 2]           1,024\n",
            "        LeakyReLU-27            [-1, 512, 2, 2]               0\n",
            "       DownSample-28            [-1, 512, 2, 2]               0\n",
            "  ConvTranspose2d-29            [-1, 512, 4, 4]       4,194,304\n",
            "      BatchNorm2d-30            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-31            [-1, 512, 4, 4]               0\n",
            "         Upsample-32           [-1, 1024, 4, 4]               0\n",
            "  ConvTranspose2d-33            [-1, 512, 8, 8]       8,388,608\n",
            "      BatchNorm2d-34            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-35            [-1, 512, 8, 8]               0\n",
            "         Upsample-36           [-1, 1024, 8, 8]               0\n",
            "  ConvTranspose2d-37          [-1, 512, 16, 16]       8,388,608\n",
            "      BatchNorm2d-38          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-39          [-1, 512, 16, 16]               0\n",
            "         Upsample-40         [-1, 1024, 16, 16]               0\n",
            "  ConvTranspose2d-41          [-1, 256, 32, 32]       4,194,304\n",
            "      BatchNorm2d-42          [-1, 256, 32, 32]             512\n",
            "             ReLU-43          [-1, 256, 32, 32]               0\n",
            "         Upsample-44          [-1, 512, 32, 32]               0\n",
            "  ConvTranspose2d-45          [-1, 128, 64, 64]       1,048,576\n",
            "      BatchNorm2d-46          [-1, 128, 64, 64]             256\n",
            "             ReLU-47          [-1, 128, 64, 64]               0\n",
            "         Upsample-48          [-1, 256, 64, 64]               0\n",
            "  ConvTranspose2d-49         [-1, 64, 128, 128]         262,144\n",
            "      BatchNorm2d-50         [-1, 64, 128, 128]             128\n",
            "             ReLU-51         [-1, 64, 128, 128]               0\n",
            "         Upsample-52        [-1, 128, 128, 128]               0\n",
            "         Upsample-53        [-1, 128, 256, 256]               0\n",
            "        ZeroPad2d-54        [-1, 128, 257, 257]               0\n",
            "           Conv2d-55          [-1, 3, 256, 256]           6,147\n",
            "             Tanh-56          [-1, 3, 256, 256]               0\n",
            "================================================================\n",
            "Total params: 41,828,099\n",
            "Trainable params: 41,828,099\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.25\n",
            "Forward/backward pass size (MB): 269.38\n",
            "Params size (MB): 159.56\n",
            "Estimated Total Size (MB): 429.19\n",
            "----------------------------------------------------------------\n",
            "torch.Size([1, 3, 256, 256])\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 128, 128]           4,160\n",
            "         LeakyReLU-2         [-1, 64, 128, 128]               0\n",
            "            Conv2d-3          [-1, 128, 64, 64]         131,200\n",
            "       BatchNorm2d-4          [-1, 128, 64, 64]             256\n",
            "         LeakyReLU-5          [-1, 128, 64, 64]               0\n",
            "            Conv2d-6          [-1, 256, 32, 32]         524,544\n",
            "       BatchNorm2d-7          [-1, 256, 32, 32]             512\n",
            "         LeakyReLU-8          [-1, 256, 32, 32]               0\n",
            "            Conv2d-9          [-1, 512, 31, 31]       2,097,664\n",
            "      BatchNorm2d-10          [-1, 512, 31, 31]           1,024\n",
            "        LeakyReLU-11          [-1, 512, 31, 31]               0\n",
            "           Conv2d-12            [-1, 1, 30, 30]           8,193\n",
            "================================================================\n",
            "Total params: 2,767,553\n",
            "Trainable params: 2,767,553\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 49152.00\n",
            "Forward/backward pass size (MB): 45.27\n",
            "Params size (MB): 10.56\n",
            "Estimated Total Size (MB): 49207.83\n",
            "----------------------------------------------------------------\n",
            "torch.Size([1, 1, 30, 30])\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(generator, input_size=(1, 256, 256))\n",
        "sample_input = torch.randn(1, 1, 256, 256).to(device)\n",
        "output = generator(sample_input)\n",
        "print(output.shape)\n",
        "\n",
        "\n",
        "summary(discriminator, input_size=[(1, 256, 256), (3, 256, 256)])\n",
        "img1 = torch.randn(1, 1, 256, 256).to(device)\n",
        "img2 = torch.randn(1, 3, 256, 256).to(device)\n",
        "output = discriminator(img1, img2)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSjWDH1VuKsc"
      },
      "source": [
        "# **Defining Loss Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCjR1RSdez69",
        "outputId": "02366999-e6e9-46eb-9fb0-cc7c8e0a91d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\IctSupport\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "C:\\Users\\IctSupport\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "\n",
        "class ChromaticAberrationLoss(nn.Module):\n",
        "  def __init__(self, device):\n",
        "    super(ChromaticAberrationLoss, self).__init__()\n",
        "    self.l1_loss = nn.L1Loss()\n",
        "\n",
        "    # Load the pre-trained VGG19 model for perceptual loss\n",
        "    vgg = models.vgg19(pretrained=True).features\n",
        "    self.vgg = nn.Sequential(*list(vgg.children())[:26])  # Extract features up to 'block4_conv4'\n",
        "    self.vgg.to(device)  # Move the VGG model to the specified device\n",
        "\n",
        "    # Freeze VGG19 parameters\n",
        "    for param in self.vgg.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "    self.device = device  # Store the device for input consistency\n",
        "\n",
        "  def forward(self, y_true, y_pred):\n",
        "    # Ensure inputs are on the same device as the model\n",
        "    y_true = y_true.to(self.device)\n",
        "    y_pred = y_pred.to(self.device)\n",
        "\n",
        "    def perceptual_loss(y_true, y_pred):\n",
        "      y_true_vgg = self.vgg(y_true)\n",
        "      y_pred_vgg = self.vgg(y_pred)\n",
        "      return F.mse_loss(y_true_vgg, y_pred_vgg)\n",
        "    \n",
        "    def spatial_loss(image):\n",
        "      loss_x = F.l1_loss(image[:, :, :-1, :], image[:, :, 1:, :])\n",
        "      loss_y = F.l1_loss(image[:, :, :, :-1], image[:, :, :, 1:])\n",
        "      return loss_x + loss_y\n",
        "\n",
        "    def edge_aware_loss(y_true, y_pred):\n",
        "      grad_true_x = y_true[:, :, 1:, :] - y_true[:, :, :-1, :]\n",
        "      grad_true_y = y_true[:, :, :, 1:] - y_true[:, :, :, :-1]\n",
        "      grad_pred_x = y_pred[:, :, 1:, :] - y_pred[:, :, :-1, :]\n",
        "      grad_pred_y = y_pred[:, :, :, 1:] - y_pred[:, :, :, :-1]\n",
        "      return F.l1_loss(grad_true_x, grad_pred_x) + F.l1_loss(grad_true_y, grad_pred_y)\n",
        "\n",
        "    return perceptual_loss(y_true, y_pred) + self.l1_loss(y_true, y_pred) + spatial_loss(y_pred) + edge_aware_loss(y_true, y_pred)\n",
        "\n",
        "criterion_GAN = nn.MSELoss()\n",
        "criterion_pixelwise = ChromaticAberrationLoss(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "cMytVBOjx5mL"
      },
      "outputs": [],
      "source": [
        "# # criterion_GAN = nn.MSELoss()\n",
        "# # criterion_pixelwise = nn.L1Loss()\n",
        "\n",
        "# \"\"\"# Chromatic Aberration Loss definition\n",
        "# class ChromaticAberrationLoss(nn.Module):\n",
        "#     def __init__(self, lambda_color=1.0, lambda_spatial=1.0, lambda_perceptual=1.0, lambda_edge=1.0):\n",
        "#         super(ChromaticAberrationLoss, self).__init__()\n",
        "#         self.lambda_color = lambda_color\n",
        "#         self.lambda_spatial = lambda_spatial\n",
        "#         self.lambda_perceptual = lambda_perceptual\n",
        "#         self.lambda_edge = lambda_edge\n",
        "\n",
        "#         # Pre-trained VGG19 model for perceptual loss\n",
        "#         vgg19 = models.vgg19(pretrained=True).features\n",
        "#         self.vgg19_block4_conv4 = nn.Sequential(*list(vgg19[:21])).eval()  # Block 4 conv 4\n",
        "#         for param in self.vgg19_block4_conv4.parameters():\n",
        "#             param.requires_grad = False\n",
        "\n",
        "#     # Convert from RGB to YUV (PyTorch version)\n",
        "#     def rgb_to_yuv(self, image):\n",
        "#         r, g, b = image[:, 0:1], image[:, 1:1], image[:, 2:1]\n",
        "#         y = 0.299 * r + 0.587 * g + 0.114 * b\n",
        "#         u = -0.14713 * r - 0.28886 * g + 0.436 * b\n",
        "#         v = 0.615 * r - 0.51499 * g - 0.10001 * b\n",
        "#         return torch.cat([y, u, v], dim=1)\n",
        "\n",
        "#     # 1. Color Discrepancy Loss (L2 Norm in YUV space)\n",
        "#     def color_loss(self, y_true, y_pred):\n",
        "#         y_true_yuv = self.rgb_to_yuv(y_true)\n",
        "#         y_pred_yuv = self.rgb_to_yuv(y_pred)\n",
        "#         return torch.mean((y_true_yuv - y_pred_yuv) ** 2)\n",
        "\n",
        "#     # 2. Spatial Consistency Loss (L1 Norm between neighboring pixels)\n",
        "#     def spatial_loss(self, image):\n",
        "#         loss_vertical = torch.mean(torch.abs(image[:, :, :-1, :] - image[:, :, 1:, :]))\n",
        "#         loss_horizontal = torch.mean(torch.abs(image[:, :, :, :-1] - image[:, :, :, 1:]))\n",
        "#         return loss_vertical + loss_horizontal\n",
        "\n",
        "#     # 3. Perceptual Loss (using VGG19)\n",
        "#     def perceptual_loss(self, y_true, y_pred):\n",
        "#         y_true_vgg = self.vgg19_block4_conv4(y_true)\n",
        "#         y_pred_vgg = self.vgg19_block4_conv4(y_pred)\n",
        "#         return torch.mean((y_true_vgg - y_pred_vgg) ** 2)\n",
        "\n",
        "#     # 4. Edge-Aware Loss (gradient difference in edge areas)\n",
        "#     def edge_aware_loss(self, y_true, y_pred):\n",
        "#         grad_true_x = y_true[:, :, 1:, :] - y_true[:, :, :-1, :]\n",
        "#         grad_true_y = y_true[:, :, :, 1:] - y_true[:, :, :, :-1]\n",
        "#         grad_pred_x = y_pred[:, :, 1:, :] - y_pred[:, :, :-1, :]\n",
        "#         grad_pred_y = y_pred[:, :, :, 1:] - y_pred[:, :, :, :-1]\n",
        "\n",
        "#         edge_loss = torch.mean(torch.abs(grad_true_x - grad_pred_x)) + \\\n",
        "#                     torch.mean(torch.abs(grad_true_y - grad_pred_y))\n",
        "#         return edge_loss\n",
        "\n",
        "#     # Total Chromatic Aberration Loss\n",
        "#     def forward(self, y_true, y_pred):\n",
        "#         color_loss_value = self.color_loss(y_true, y_pred)\n",
        "#         spatial_loss_value = self.spatial_loss(y_pred)\n",
        "#         perceptual_loss_value = self.perceptual_loss(y_true, y_pred)\n",
        "#         edge_loss_value = self.edge_aware_loss(y_true, y_pred)\n",
        "\n",
        "#         total_loss = (self.lambda_color * color_loss_value) + \\\n",
        "#                      (self.lambda_spatial * spatial_loss_value) + \\\n",
        "#                      (self.lambda_perceptual * perceptual_loss_value) + \\\n",
        "#                      (self.lambda_edge * edge_loss_value)\n",
        "\n",
        "#         return total_loss\"\"\"\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# from torchvision import models\n",
        "\n",
        "# # # Convert RGB to LAB using PyTorch\n",
        "# # def rgb_to_lab(image):\n",
        "# #     # The conversion logic from RGB to LAB will be approximated.\n",
        "# #     # For simplicity, here we assume the image is normalized to [0, 1].\n",
        "# #     image = (image + 1) / 2  # Denormalize from [-1, 1] to [0, 1]\n",
        "# #     image = image.clamp(0, 1)  # Ensure pixel values are within [0, 1]\n",
        "\n",
        "# #     # You can use a library like OpenCV to convert to LAB, but here's a placeholder\n",
        "# #     # You would need to use `cv2.cvtColor(image, cv2.COLOR_RGB2LAB)` with actual data.\n",
        "# #     # Placeholder conversion: Assume yuv is LAB (for simplicity)\n",
        "# #     return image  # This would be replaced by actual LAB conversion logic\n",
        "\n",
        "# # # Chromatic Aberration Loss in PyTorch\n",
        "# # class ChromaticAberrationLoss(nn.Module):\n",
        "# #     def __init__(self, lambda_color=1.0, lambda_spatial=1.0, lambda_perceptual=1.0, lambda_edge=1.0):\n",
        "# #         super(ChromaticAberrationLoss, self).__init__()\n",
        "# #         self.lambda_color = lambda_color\n",
        "# #         self.lambda_spatial = lambda_spatial\n",
        "# #         self.lambda_perceptual = lambda_perceptual\n",
        "# #         self.lambda_edge = lambda_edge\n",
        "\n",
        "# #         # Load the pre-trained VGG19 model for perceptual loss\n",
        "# #         vgg = models.vgg19(pretrained=True).features\n",
        "# #         self.vgg = nn.Sequential(*list(vgg.children())[:22])  # Extract up to 'block4_conv4'\n",
        "# #         for param in self.vgg.parameters():\n",
        "# #             param.requires_grad = False  # Freeze VGG19 parameters\n",
        "\n",
        "# #     def forward(self, y_true, y_pred):\n",
        "# #         # 1. Color Discrepancy Loss (L2 Norm in LAB space)\n",
        "# #         y_true_lab = rgb_to_lab(y_true)\n",
        "# #         y_pred_lab = rgb_to_lab(y_pred)\n",
        "# #         color_loss = F.mse_loss(y_true_lab, y_pred_lab)\n",
        "\n",
        "# #         # 2. Spatial Consistency Loss (L1 Norm between neighboring pixels)\n",
        "# #         def spatial_loss(image):\n",
        "# #             loss_x = F.l1_loss(image[:, :, :-1, :], image[:, :, 1:, :])\n",
        "# #             loss_y = F.l1_loss(image[:, :, :, :-1], image[:, :, :, 1:])\n",
        "# #             return loss_x + loss_y\n",
        "\n",
        "# #         spatial_loss_value = spatial_loss(y_pred)\n",
        "\n",
        "# #         # 3. Perceptual Loss using VGG19 features\n",
        "# #         def perceptual_loss(y_true, y_pred):\n",
        "# #             y_true_vgg = self.vgg(y_true)\n",
        "# #             y_pred_vgg = self.vgg(y_pred)\n",
        "# #             return F.mse_loss(y_true_vgg, y_pred_vgg)\n",
        "\n",
        "# #         perceptual_loss_value = perceptual_loss(y_true, y_pred)\n",
        "\n",
        "# #         # 4. Edge-Aware Loss (gradient difference in edge areas)\n",
        "# #         def edge_aware_loss(y_true, y_pred):\n",
        "# #             grad_true_x = y_true[:, :, 1:, :] - y_true[:, :, :-1, :]\n",
        "# #             grad_true_y = y_true[:, :, :, 1:] - y_true[:, :, :, :-1]\n",
        "# #             grad_pred_x = y_pred[:, :, 1:, :] - y_pred[:, :, :-1, :]\n",
        "# #             grad_pred_y = y_pred[:, :, :, 1:] - y_pred[:, :, :, :-1]\n",
        "# #             edge_loss = F.l1_loss(grad_true_x, grad_pred_x) + F.l1_loss(grad_true_y, grad_pred_y)\n",
        "# #             return edge_loss\n",
        "\n",
        "# #         edge_loss_value = edge_aware_loss(y_true, y_pred)\n",
        "\n",
        "# #         # Total Chromatic Aberration Loss\n",
        "# #         total_loss = (self.lambda_color * color_loss) + \\\n",
        "# #                      (self.lambda_spatial * spatial_loss_value) + \\\n",
        "# #                      (self.lambda_perceptual * perceptual_loss_value) + \\\n",
        "# #                      (self.lambda_edge * edge_loss_value)\n",
        "\n",
        "# #         return total_loss\n",
        "\n",
        "# class ChromaticAberrationLoss(nn.Module):\n",
        "#     def __init__(self, device\n",
        "#                 #  , lambda_color=1.0, lambda_spatial=1.0, lambda_perceptual=1.0, lambda_edge=1.0\n",
        "#                  ):\n",
        "#         super(ChromaticAberrationLoss, self).__init__()\n",
        "#         # self.lambda_color = lambda_color\n",
        "#         # self.lambda_spatial = lambda_spatial\n",
        "#         # self.lambda_perceptual = lambda_perceptual\n",
        "#         # self.lambda_edge = lambda_edge\n",
        "#         self.l1_loss = nn.L1Loss()\n",
        "\n",
        "\n",
        "#         # Load the pre-trained VGG19 model for perceptual loss and move it to the appropriate device\n",
        "#         vgg = models.vgg19(pretrained=True).features\n",
        "#         self.vgg = nn.Sequential(*list(vgg.children())[:22])  # Extract up to 'block4_conv4'\n",
        "#         self.vgg.to(device)  # Move the VGG model to the appropriate device (GPU/CPU)\n",
        "\n",
        "#         for param in self.vgg.parameters():\n",
        "#             param.requires_grad = False  # Freeze VGG19 parameters\n",
        "\n",
        "#         self.device = device  # Store device for later use\n",
        "\n",
        "#     def forward(self, y_true, y_pred):\n",
        "#         # Move inputs to the same device as the model (VGG)\n",
        "#         y_true = y_true.to(self.device)\n",
        "#         y_pred = y_pred.to(self.device)\n",
        "\n",
        "#         # # 1. Color Discrepancy Loss (L2 Norm in LAB space)\n",
        "#         # y_true_lab = rgb_to_lab(y_true)\n",
        "#         # y_pred_lab = rgb_to_lab(y_pred)\n",
        "#         # color_loss = F.mse_loss(y_true_lab, y_pred_lab)\n",
        "\n",
        "#         # # 2. Spatial Consistency Loss (L1 Norm between neighboring pixels)\n",
        "#         # def spatial_loss(image):\n",
        "#         #     loss_x = F.l1_loss(image[:, :, :-1, :], image[:, :, 1:, :])\n",
        "#         #     loss_y = F.l1_loss(image[:, :, :, :-1], image[:, :, :, 1:])\n",
        "#         #     return loss_x + loss_y\n",
        "\n",
        "#         # spatial_loss_value = spatial_loss(y_pred)\n",
        "\n",
        "#         # 3. Perceptual Loss using VGG19 features\n",
        "#         def perceptual_loss(y_true, y_pred):\n",
        "#             y_true_vgg = self.vgg(y_true)\n",
        "#             y_pred_vgg = self.vgg(y_pred)\n",
        "#             return F.mse_loss(y_true_vgg, y_pred_vgg)\n",
        "\n",
        "#         perceptual_loss_value = perceptual_loss(y_true, y_pred) + self.l1_loss(y_true, y_pred)\n",
        "\n",
        "#         # # 4. Edge-Aware Loss (gradient difference in edge areas)\n",
        "#         # def edge_aware_loss(y_true, y_pred):\n",
        "#         #     grad_true_x = y_true[:, :, 1:, :] - y_true[:, :, :-1, :]\n",
        "#         #     grad_true_y = y_true[:, :, :, 1:] - y_true[:, :, :, :-1]\n",
        "#         #     grad_pred_x = y_pred[:, :, 1:, :] - y_pred[:, :, :-1, :]\n",
        "#         #     grad_pred_y = y_pred[:, :, :, 1:] - y_pred[:, :, :, :-1]\n",
        "#         #     edge_loss = F.l1_loss(grad_true_x, grad_pred_x) + F.l1_loss(grad_true_y, grad_pred_y)\n",
        "#         #     return edge_loss\n",
        "\n",
        "#         # edge_loss_value = edge_aware_loss(y_true, y_pred)\n",
        "\n",
        "#         # # Total Chromatic Aberration Loss\n",
        "#         # total_loss = (self.lambda_color * color_loss) + \\\n",
        "#         #              (self.lambda_spatial * spatial_loss_value) + \\\n",
        "#         #              (self.lambda_perceptual * perceptual_loss_value) + \\\n",
        "#         #              (self.lambda_edge * edge_loss_value)\n",
        "\n",
        "#         return perceptual_loss_value\n",
        "\n",
        "# # Replace L1 loss with Chromatic Aberration Loss\n",
        "# criterion_GAN = nn.MSELoss()\n",
        "# criterion_pixelwise = ChromaticAberrationLoss(device)\n",
        "\n",
        "# # Example usage in your training loop\n",
        "# # Assuming the rest of your training setup is the same\n",
        "# # loss_pixel = criterion_pixelwise(generated_imgs, target_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### lossend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Ay9oS9e1cuK2"
      },
      "outputs": [],
      "source": [
        "optimizer_G = optim.Adam(generator.parameters(), lr=0.002, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.002, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XnfxhzwcuK3"
      },
      "source": [
        "# Dataset class for handling SAR input and DATALOADER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lBVjvPvJcuK3"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the dataset class\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, SAR_root, color_root=None, transforms_=None):\n",
        "        self.SAR_root = SAR_root\n",
        "        self.color_root = color_root\n",
        "        self.transforms = transforms_\n",
        "\n",
        "        # Get sorted list of SAR images\n",
        "        self.SAR_images = sorted([f for f in os.listdir(SAR_root)[:12000] if f.endswith('.png')])\n",
        "\n",
        "        # If color images are provided, get sorted list of color images\n",
        "        if color_root:\n",
        "            self.color_images = sorted([f for f in os.listdir(color_root)[:12000] if f.endswith('.png')])\n",
        "            # Ensure the number of SAR and color images are the same\n",
        "            assert len(self.SAR_images) == len(self.color_images), \"Mismatch between SAR and color image count\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.SAR_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load SAR image\n",
        "        SAR_image_path = os.path.join(self.SAR_root, self.SAR_images[idx])\n",
        "        SAR_image = Image.open(SAR_image_path).convert('L')  # Grayscale (1 channel)\n",
        "\n",
        "        if self.color_root:\n",
        "            # Load corresponding color image\n",
        "            color_image_path = os.path.join(self.color_root, self.color_images[idx])\n",
        "            color_image = Image.open(color_image_path).convert('RGB')  # RGB (3 channels)\n",
        "\n",
        "            # Apply transformations if available\n",
        "            if self.transforms:\n",
        "                SAR_image = self.transforms(SAR_image)\n",
        "                color_image = self.transforms(color_image)\n",
        "\n",
        "            return SAR_image, color_image\n",
        "        else:\n",
        "            # Apply transformations to SAR image only\n",
        "            if self.transforms:\n",
        "                SAR_image = self.transforms(SAR_image)\n",
        "            return SAR_image\n",
        "\n",
        "# Define the transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),  # Resize to match your model input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize (use 3 channels normalization if needed for color)\n",
        "])\n",
        "\n",
        "# DataLoader for training\n",
        "dataloader = DataLoader(\n",
        "    ImageDataset(\n",
        "        SAR_root=\"C:/mini_ProjectSAR/sardata/Complete(without Duplicates)/x\",  # Path to SAR images\n",
        "        color_root=\"C:/mini_ProjectSAR/sardata/Complete(without Duplicates)/y\",  # Path to color images\n",
        "        transforms_=transform\n",
        "    ),\n",
        "    batch_size=32,  # Adjust the batch size as needed\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh6bcwQWcuK6"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\IctSupport\\AppData\\Local\\Temp\\ipykernel_13296\\865705828.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint_G = torch.load(\"generator14.pth\", map_location=torch.device('cuda'))\n",
            "C:\\Users\\IctSupport\\AppData\\Local\\Temp\\ipykernel_13296\\865705828.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint_D = torch.load(\"discriminator14.pth\", map_location=torch.device('cuda'))\n"
          ]
        }
      ],
      "source": [
        "checkpoint_G = torch.load(\"generator14.pth\", map_location=torch.device('cuda'))\n",
        "generator.load_state_dict(checkpoint_G['model_state_dict'])\n",
        "optimizer_G.load_state_dict(checkpoint_G['optimizer_state_dict'])\n",
        "\n",
        "checkpoint_D = torch.load(\"discriminator14.pth\", map_location=torch.device('cuda'))\n",
        "discriminator.load_state_dict(checkpoint_D['model_state_dict'])\n",
        "optimizer_D.load_state_dict(checkpoint_D['optimizer_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nVgk4IlicuK6",
        "outputId": "e7e52ca7-61b0-47cd-ca5d-fb3ba9d04aa1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 16/85] [Avg D loss: 0.2276] [Avg G loss: 9.6004]\n",
            "Elapsed Time: 4101.99 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 17/85] [Avg D loss: 0.2201] [Avg G loss: 9.5122]\n",
            "Elapsed Time: 3590.39 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 18/85] [Avg D loss: 0.2248] [Avg G loss: 9.4157]\n",
            "Elapsed Time: 3590.83 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 19/85] [Avg D loss: 0.2104] [Avg G loss: 9.3337]\n",
            "Elapsed Time: 3590.05 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 20/85] [Avg D loss: 0.2083] [Avg G loss: 9.2290]\n",
            "Elapsed Time: 3589.51 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 21/85] [Avg D loss: 0.2112] [Avg G loss: 9.1171]\n",
            "Elapsed Time: 3591.39 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 22/85] [Avg D loss: 0.1967] [Avg G loss: 9.0274]\n",
            "Elapsed Time: 3588.72 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 23/85] [Avg D loss: 0.1654] [Avg G loss: 8.9635]\n",
            "Elapsed Time: 3588.62 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 24/85] [Avg D loss: 0.1786] [Avg G loss: 8.9299]\n",
            "Elapsed Time: 3588.48 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 25/85] [Avg D loss: 0.1738] [Avg G loss: 8.9079]\n",
            "Elapsed Time: 3599.42 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 26/85] [Avg D loss: 0.1469] [Avg G loss: 8.8053]\n",
            "Elapsed Time: 3600.07 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 27/85] [Avg D loss: 0.1707] [Avg G loss: 8.7087]\n",
            "Elapsed Time: 3616.31 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 28/85] [Avg D loss: 0.1373] [Avg G loss: 8.6055]\n",
            "Elapsed Time: 3591.77 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 29/85] [Avg D loss: 0.1361] [Avg G loss: 8.4982]\n",
            "Elapsed Time: 3589.28 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 30/85] [Avg D loss: 0.1273] [Avg G loss: 8.3938]\n",
            "Elapsed Time: 3589.06 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 31/85] [Avg D loss: 0.1257] [Avg G loss: 8.3139]\n",
            "Elapsed Time: 3589.96 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 32/85] [Avg D loss: 0.1243] [Avg G loss: 8.1948]\n",
            "Elapsed Time: 3589.45 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 33/85] [Avg D loss: 0.1237] [Avg G loss: 8.0834]\n",
            "Elapsed Time: 3588.99 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 34/85] [Avg D loss: 0.1221] [Avg G loss: 7.9720]\n",
            "Elapsed Time: 3588.61 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 35/85] [Avg D loss: 0.1104] [Avg G loss: 7.8817]\n",
            "Elapsed Time: 3589.55 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 36/85] [Avg D loss: 0.1176] [Avg G loss: 7.7984]\n",
            "Elapsed Time: 4529.54 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 37/85] [Avg D loss: 0.1148] [Avg G loss: 7.6849]\n",
            "Elapsed Time: 5000.02 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 38/85] [Avg D loss: 0.1093] [Avg G loss: 7.6042]\n",
            "Elapsed Time: 4997.24 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 39/85] [Avg D loss: 0.1109] [Avg G loss: 7.5272]\n",
            "Elapsed Time: 4996.64 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 40/85] [Avg D loss: 0.1027] [Avg G loss: 7.4281]\n",
            "Elapsed Time: 4995.72 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 41/85] [Avg D loss: 0.0907] [Avg G loss: 7.3357]\n",
            "Elapsed Time: 4993.50 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 42/85] [Avg D loss: 0.0943] [Avg G loss: 7.2726]\n",
            "Elapsed Time: 4993.77 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 43/85] [Avg D loss: 0.0913] [Avg G loss: 7.1870]\n",
            "Elapsed Time: 4994.72 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 44/85] [Avg D loss: 0.0881] [Avg G loss: 7.1142]\n",
            "Elapsed Time: 4993.11 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 45/85] [Avg D loss: 0.0819] [Avg G loss: 7.0292]\n",
            "Elapsed Time: 5000.08 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 46/85] [Avg D loss: 0.0851] [Avg G loss: 6.9468]\n",
            "Elapsed Time: 5002.76 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 47/85] [Avg D loss: 0.0796] [Avg G loss: 6.8801]\n",
            "Elapsed Time: 4995.32 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 48/85] [Avg D loss: 0.0748] [Avg G loss: 6.8279]\n",
            "Elapsed Time: 4992.75 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 49/85] [Avg D loss: 0.0794] [Avg G loss: 6.7625]\n",
            "Elapsed Time: 4994.31 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 50/85] [Avg D loss: 0.0788] [Avg G loss: 6.7085]\n",
            "Elapsed Time: 4993.43 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 51/85] [Avg D loss: 0.0730] [Avg G loss: 6.6388]\n",
            "Elapsed Time: 4992.81 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 52/85] [Avg D loss: 0.0718] [Avg G loss: 6.5963]\n",
            "Elapsed Time: 4996.51 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 53/85] [Avg D loss: 0.0722] [Avg G loss: 6.5220]\n",
            "Elapsed Time: 4995.28 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 54/85] [Avg D loss: 0.0720] [Avg G loss: 6.4609]\n",
            "Elapsed Time: 5125.76 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 55/85] [Avg D loss: 0.0677] [Avg G loss: 6.4472]\n",
            "Elapsed Time: 5194.95 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 56/85] [Avg D loss: 0.0644] [Avg G loss: 6.3908]\n",
            "Elapsed Time: 5192.60 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 57/85] [Avg D loss: 0.0768] [Avg G loss: 6.3291]\n",
            "Elapsed Time: 5191.79 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 58/85] [Avg D loss: 0.0691] [Avg G loss: 6.2880]\n",
            "Elapsed Time: 5191.52 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 59/85] [Avg D loss: 0.0664] [Avg G loss: 6.2639]\n",
            "Elapsed Time: 5191.44 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 60/85] [Avg D loss: 0.0793] [Avg G loss: 6.2425]\n",
            "Elapsed Time: 5191.81 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 61/85] [Avg D loss: 0.0727] [Avg G loss: 6.2053]\n",
            "Elapsed Time: 5192.32 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 62/85] [Avg D loss: 0.0695] [Avg G loss: 6.1652]\n",
            "Elapsed Time: 5199.79 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 63/85] [Avg D loss: 0.0717] [Avg G loss: 6.1171]\n",
            "Elapsed Time: 5202.86 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 64/85] [Avg D loss: 0.0823] [Avg G loss: 6.0848]\n",
            "Elapsed Time: 5192.53 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 65/85] [Avg D loss: 0.0654] [Avg G loss: 6.0153]\n",
            "Elapsed Time: 5192.44 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 66/85] [Avg D loss: 0.0672] [Avg G loss: 5.9912]\n",
            "Elapsed Time: 5192.22 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 67/85] [Avg D loss: 0.0692] [Avg G loss: 5.9743]\n",
            "Elapsed Time: 5192.53 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 68/85] [Avg D loss: 0.0611] [Avg G loss: 5.9744]\n",
            "Elapsed Time: 5192.63 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 69/85] [Avg D loss: 0.0603] [Avg G loss: 5.9127]\n",
            "Elapsed Time: 5192.74 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 70/85] [Avg D loss: 0.0621] [Avg G loss: 5.8893]\n",
            "Elapsed Time: 5193.41 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 71/85] [Avg D loss: 0.0657] [Avg G loss: 5.8325]\n",
            "Elapsed Time: 5194.28 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 72/85] [Avg D loss: 0.0650] [Avg G loss: 5.8189]\n",
            "Elapsed Time: 5193.85 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 73/85] [Avg D loss: 0.0665] [Avg G loss: 5.7653]\n",
            "Elapsed Time: 5194.92 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 74/85] [Avg D loss: 0.0622] [Avg G loss: 5.7646]\n",
            "Elapsed Time: 5203.70 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 75/85] [Avg D loss: 0.0654] [Avg G loss: 5.7486]\n",
            "Elapsed Time: 5194.15 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 76/85] [Avg D loss: 0.0669] [Avg G loss: 5.7149]\n",
            "Elapsed Time: 5191.71 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 77/85] [Avg D loss: 0.0678] [Avg G loss: 5.6892]\n",
            "Elapsed Time: 5191.02 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 78/85] [Avg D loss: 0.0544] [Avg G loss: 5.6511]\n",
            "Elapsed Time: 5191.87 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 79/85] [Avg D loss: 0.0655] [Avg G loss: 5.6216]\n",
            "Elapsed Time: 5207.12 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 80/85] [Avg D loss: 0.0661] [Avg G loss: 5.6227]\n",
            "Elapsed Time: 5193.38 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 81/85] [Avg D loss: 0.0669] [Avg G loss: 5.6076]\n",
            "Elapsed Time: 5192.35 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 82/85] [Avg D loss: 0.0580] [Avg G loss: 5.5320]\n",
            "Elapsed Time: 5190.51 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 83/85] [Avg D loss: 0.0739] [Avg G loss: 5.5369]\n",
            "Elapsed Time: 5190.84 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 84/85] [Avg D loss: 0.0647] [Avg G loss: 5.5428]\n",
            "Elapsed Time: 5191.10 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 85/85] [Avg D loss: 0.0703] [Avg G loss: 5.4954]\n",
            "Elapsed Time: 5191.30 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 86/85] [Avg D loss: 0.0639] [Avg G loss: 5.4981]\n",
            "Elapsed Time: 5362.10 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 87/85] [Avg D loss: 0.0646] [Avg G loss: 5.4953]\n",
            "Elapsed Time: 5023.37 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 88/85] [Avg D loss: 0.0755] [Avg G loss: 5.4372]\n",
            "Elapsed Time: 4998.60 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 89/85] [Avg D loss: 0.0705] [Avg G loss: 5.4383]\n",
            "Elapsed Time: 4999.77 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 90/85] [Avg D loss: 0.0634] [Avg G loss: 5.3937]\n",
            "Elapsed Time: 5001.78 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 91/85] [Avg D loss: 0.0674] [Avg G loss: 5.4192]\n",
            "Elapsed Time: 4995.58 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 92/85] [Avg D loss: 0.0685] [Avg G loss: 5.3857]\n",
            "Elapsed Time: 4995.57 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 93/85] [Avg D loss: 0.0681] [Avg G loss: 5.3419]\n",
            "Elapsed Time: 4994.55 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 94/85] [Avg D loss: 0.0741] [Avg G loss: 5.3533]\n",
            "Elapsed Time: 4995.64 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 95/85] [Avg D loss: 0.0657] [Avg G loss: 5.3436]\n",
            "Elapsed Time: 4996.45 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 96/85] [Avg D loss: 0.0723] [Avg G loss: 5.2929]\n",
            "Elapsed Time: 5019.45 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 97/85] [Avg D loss: 0.0752] [Avg G loss: 5.3201]\n",
            "Elapsed Time: 4996.15 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 98/85] [Avg D loss: 0.0657] [Avg G loss: 5.3091]\n",
            "Elapsed Time: 4996.48 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 99/85] [Avg D loss: 0.0741] [Avg G loss: 5.2867]\n",
            "Elapsed Time: 4994.16 seconds | ETA: 0.00 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 100/85] [Avg D loss: 0.0871] [Avg G loss: 5.2691]\n",
            "Elapsed Time: 4993.72 seconds | ETA: 0.00 seconds\n",
            "All models saved.\n"
          ]
        }
      ],
      "source": [
        "epochs_completed = 15\n",
        "\n",
        "patience = 5\n",
        "best_loss_G = float('inf')\n",
        "best_loss_D = float('inf')\n",
        "no_improvement_G = 0\n",
        "no_improvement_D = 0\n",
        "no_of_epochs = 100 - epochs_completed\n",
        "\n",
        "# Get the total number of batches\n",
        "total_batches = len(dataloader)\n",
        "\n",
        "# Start the training loop\n",
        "for i in range(no_of_epochs):\n",
        "    epoch = i + epochs_completed\n",
        "    start_time = time.time()  # Record start time for ETA calculation\n",
        "    epoch_loss_G = 0\n",
        "    epoch_loss_D = 0\n",
        "\n",
        "    dataloader_tqdm = tqdm(dataloader, desc=f'Epoch {epoch+1}/{no_of_epochs + epochs_completed}', leave=False)\n",
        "\n",
        "    for i, (SAR_imgs, color_imgs) in enumerate(dataloader_tqdm):\n",
        "        SAR_imgs = SAR_imgs.to(device)\n",
        "        color_imgs = color_imgs.to(device)\n",
        "\n",
        "        valid = torch.ones((SAR_imgs.size(0), 1, 30, 30), requires_grad=False).to(device)  # Adjust to match image size\n",
        "        fake = torch.zeros((SAR_imgs.size(0), 1, 30, 30), requires_grad=False).to(device)  # Adjust to match image size\n",
        "\n",
        "        # ------------------\n",
        "        # Train Generator\n",
        "        # ------------------\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        fake_imgs = generator(SAR_imgs)\n",
        "        # Resize fake images to match color images size if necessary\n",
        "        fake_imgs_resized = F.interpolate(fake_imgs, size=color_imgs.size()[2:], mode='bilinear', align_corners=False)\n",
        "\n",
        "        # Ensure that fake_imgs_resized and color_imgs have the same size\n",
        "        assert fake_imgs_resized.size() == color_imgs.size(), f\"Size mismatch: {fake_imgs_resized.size()} vs {color_imgs.size()}\"\n",
        "\n",
        "        # GAN loss (Discriminator should classify fake images as valid)\n",
        "        loss_GAN = criterion_GAN(discriminator(fake_imgs_resized, SAR_imgs), valid)\n",
        "\n",
        "        # Pixel-wise loss\n",
        "        loss_pixelwise = criterion_pixelwise(fake_imgs_resized, color_imgs)\n",
        "\n",
        "        # Total generator loss\n",
        "        loss_G = loss_GAN + loss_pixelwise\n",
        "        loss_G.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        nn.utils.clip_grad_norm_(generator.parameters(), max_norm=1.0)\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ------------------\n",
        "        # Train Discriminator\n",
        "        # ------------------\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Real images (Discriminator should classify real images as valid)\n",
        "        loss_real = criterion_GAN(discriminator(color_imgs, SAR_imgs), valid)\n",
        "\n",
        "        # Fake images (Discriminator should classify generated images as fake)\n",
        "        loss_fake = criterion_GAN(discriminator(fake_imgs_resized.detach(), SAR_imgs), fake)\n",
        "\n",
        "        # Total discriminator loss\n",
        "        loss_D = loss_real + loss_fake\n",
        "        loss_D.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        nn.utils.clip_grad_norm_(discriminator.parameters(), max_norm=1.0)\n",
        "        optimizer_D.step()\n",
        "\n",
        "        epoch_loss_G += loss_G.item()\n",
        "        epoch_loss_D += loss_D.item()\n",
        "\n",
        "        # Calculate elapsed time and ETA\n",
        "        elapsed_time = time.time() - start_time\n",
        "        avg_time_per_batch = elapsed_time / (i + 1)\n",
        "        remaining_batches = total_batches - (i + 1)\n",
        "        eta = avg_time_per_batch * remaining_batches\n",
        "\n",
        "        # Update the tqdm description with ETA\n",
        "        dataloader_tqdm.set_postfix({\n",
        "            'D loss': f'{loss_D.item():.4f}',\n",
        "            'G loss': f'{loss_G.item():.4f}',\n",
        "            'ETA': f'{eta:.2f}s'\n",
        "        })\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    avg_loss_G = epoch_loss_G / len(dataloader)\n",
        "    avg_loss_D = epoch_loss_D / len(dataloader)\n",
        "\n",
        "    print(f\"\\n[Epoch {epoch+1}/{no_of_epochs + epochs_completed}] [Avg D loss: {avg_loss_D:.4f}] [Avg G loss: {avg_loss_G:.4f}]\")\n",
        "    print(f\"Elapsed Time: {elapsed_time:.2f} seconds | ETA: {eta:.2f} seconds\")\n",
        "\n",
        "    # Early stopping and model checkpointing\n",
        "    if avg_loss_G < best_loss_G:\n",
        "        best_loss_G = avg_loss_G\n",
        "        no_improvement_G = 0\n",
        "        best_generator_state = generator.state_dict()\n",
        "    else:\n",
        "        no_improvement_G += 1\n",
        "\n",
        "    if avg_loss_D < best_loss_D:\n",
        "        best_loss_D = avg_loss_D\n",
        "        no_improvement_D = 0\n",
        "        best_discriminator_state = discriminator.state_dict()\n",
        "    else:\n",
        "        no_improvement_D += 1\n",
        "\n",
        "    # Check for early stopping\n",
        "    if no_improvement_G >= patience and no_improvement_D >= patience:\n",
        "        print(\"Early stopping triggered. Training stopped.\")\n",
        "        break\n",
        "\n",
        "    save_path_generator = f'generator{epoch}.pth'\n",
        "    save_path_discriminator = f'discriminator{epoch}.pth'\n",
        "\n",
        "    torch.save({\n",
        "        'model_state_dict': best_generator_state,\n",
        "        'optimizer_state_dict': optimizer_G.state_dict(),\n",
        "        'loss': best_loss_G,\n",
        "    }, save_path_generator)\n",
        "\n",
        "    torch.save({\n",
        "        'model_state_dict': best_discriminator_state,\n",
        "        'optimizer_state_dict': optimizer_D.state_dict(),\n",
        "        'loss': best_loss_D,\n",
        "    }, save_path_discriminator)\n",
        "\n",
        "print(\"All models saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hteYtzvcuK8"
      },
      "source": [
        "# Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eDbWZhYncuK9",
        "outputId": "ff8f6700-d649-414f-a031-25758c3d68f7"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# from PIL import Image\n",
        "\n",
        "# # Create Testpred directory if it doesn't exist\n",
        "# save_dir = \"Testpred\"\n",
        "# os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# # Load the generator model for testing\n",
        "# checkpoint_G = torch.load(\"generator1.pth\", map_location=torch.device('cpu'))\n",
        "# generator.load_state_dict(checkpoint_G['model_state_dict'])\n",
        "# optimizer_G.load_state_dict(checkpoint_G['optimizer_state_dict'])\n",
        "# generator.eval()  # Set the generator to evaluation mode\n",
        "\n",
        "\n",
        "# # Load test dataset for inference\n",
        "# test_dataset = ImageDataset(\n",
        "#     SAR_root=\"Test\",\n",
        "#     color_root=None,  # Not needed for testing\n",
        "#     transforms_=transform\n",
        "# )\n",
        "\n",
        "# test_dataloader = DataLoader(\n",
        "#     test_dataset,\n",
        "#     batch_size=16,\n",
        "#     shuffle=False\n",
        "# )\n",
        "\n",
        "\n",
        "# # Function to test the generator, display images, and save them\n",
        "# def test_generator(generator, test_loader, num_images=5, save_dir=save_dir):\n",
        "#     generator.eval()  # Set the generator to evaluation mode\n",
        "#     with torch.no_grad():  # Disable gradient calculation for faster inference\n",
        "#         for i, SAR_imgs in enumerate(test_loader):\n",
        "#             SAR_imgs = SAR_imgs.to(device)  # Move SAR images to the device\n",
        "#             generated_imgs = generator(SAR_imgs)\n",
        "#             generated_imgs = 0.5 * (generated_imgs + 1)  # Denormalize from [-1, 1] to [0, 1]\n",
        "#             SAR_imgs = SAR_imgs.cpu()\n",
        "#             generated_imgs = generated_imgs.cpu()\n",
        "\n",
        "#             # Display the first few images in the batch\n",
        "#             for j in range(min(num_images, SAR_imgs.size(0))):\n",
        "#                 fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "#                 # Input SAR image\n",
        "#                 axes[0].imshow(SAR_imgs[j].squeeze(0), cmap='gray')  # Display as grayscale\n",
        "#                 axes[0].set_title('Input SAR Image')\n",
        "#                 axes[0].axis('off')\n",
        "\n",
        "#                 # Output colorized image\n",
        "#                 axes[1].imshow(transforms.ToPILImage()(generated_imgs[j]))\n",
        "#                 axes[1].set_title('Generated Color Image')\n",
        "#                 axes[1].axis('off')\n",
        "\n",
        "#                 plt.show()\n",
        "\n",
        "#                 # Save the generated image\n",
        "#                 generated_img_pil = transforms.ToPILImage()(generated_imgs[j])\n",
        "#                 img_save_path = os.path.join(save_dir, f'generated_image_{i}_{j}.png')\n",
        "#                 generated_img_pil.save(img_save_path)\n",
        "#                 print(f\"Saved: {img_save_path}\")\n",
        "\n",
        "# # Run testing, visualization, and saving\n",
        "# test_generator(generator, test_dataloader, num_images=6)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
